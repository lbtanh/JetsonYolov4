<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="face-mask-yolov4-detector---nvidia-jetson-nano">Face Mask Yolov4 detector - Nvidia Jetson Nano</h1>
<p><img src="images/MaskDetector.gif" alt="Mask Detector"></p>
<h2 id="citations">Citations</h2>
<p>This is a project for the Jetson Community and couldn't be possible without the effort of other developers. All the YoloV4 / Darknet code and documentation can be found here:</p>
<ul>
<li><a href="https://pjreddie.com/darknet/">Pjreddie - Darknet</a></li>
<li><a href="https://github.com/AlexeyAB/darknet">AlexeyAB/darknet</a></li>
</ul>
<h2 id="index">Index</h2>
<ol start="0">
<li><a href="#previous-tips">Previous tips</a></li>
<li><a href="#Dataset">Dataset</a>
<ol>
<li><a href="#Downloading-the-dataset">Downloading the dataset</a></li>
<li><a href="#Conversion-to-Yolo-format">Conversion to Yolo format</a></li>
</ol>
</li>
<li><a href="#YoloV4">YoloV4</a>
<ol>
<li><a href="#Compiling-YoloV4-on-Nvidia-Jetson-Nano">Compiling YoloV4 on Nvidia Jetson Nano</a></li>
<li><a href="#Testing-YoloV4-with-COCO">Testing YoloV4 with COCO</a></li>
<li><a href="#Training-the-Mask-Detector">Training the Mask Detector</a></li>
<li><a href="#Led-Control">Led Control</a></li>
</ol>
</li>
</ol>
<h2 id="previous-tips">Previous tips</h2>
<p>During the development of this project I use SSH, SCP and VNC Viewer for controlling and file-transfer from my PC to Jetson Nano board. You can control it directly from the board with a keyboard and mouse but this way is more unconfortable from my point of view:</p>
<ul>
<li><a href="https://developer.nvidia.com/embedded/learn/tutorials/vnc-setup">Setup VNC server on the Jetson developer kit</a></li>
<li><a href="https://phoenixnap.com/kb/ssh-to-connect-to-remote-server-linux-or-windows">How To Use SSH To Connect To A Remote Server In Linux Or Windows</a></li>
<li><a href="https://linuxize.com/post/how-to-use-scp-command-to-securely-transfer-files">How to Use SCP Command to Securely Transfer Files</a></li>
</ul>
<h2 id="dataset">Dataset</h2>
<p>For this project I used the Kaggle's <a href="https://www.kaggle.com/andrewmvd/face-mask-detection">Face Mask Detection</a> dataset with 853 images belonging to 3 classes. Each image has one or many bounding boxes.</p>
<p>The classes are:</p>
<ul>
<li>With mask</li>
<li>Without mask</li>
<li>Mask worn incorrectly</li>
</ul>
<p>I recomend use <a href="https://datasetsearch.research.google.com/">Google Dataset Search</a> to find any kind of dataset, in this case this dataset maybe its a bit small but I've got a good accuracy, if you want you can make it bigger with your own images or any other dataset.</p>
<h3 id="conversion-to-yolo-format">Conversion to Yolo format</h3>
<p>Yolo needs an specific notation for train the model and .jpg file format, so first of all you have to go to images folder and run:</p>
<pre class="hljs"><code><div>$&gt; sudo apt-get install imagemagick

$&gt; #mogrify -format jpg *.png
# create new folder for output images
$&gt; mkdir ../obj &amp; mogrify -format jpg -path ../obj *.png
</div></code></pre>
<pre class="hljs"><code><div>$&gt; python3 xml_to_yolo.py
</div></code></pre>
<p>If you haven't any library just install it with pip/pip3.</p>
<p>After that you will have one .txt per .xml file, train.txt and test.txt, obj folder contain the same format as darknet, now just copy it into darknet/data/ (These file has a split 90/10 of the total of bounding boxes).</p>
<pre class="hljs"><code><div>cp -r obj ../darknet/data/ 
cp train.txt ../darknet/data/ 
cp test.txt ../darknet/data/ 
cp obj.names ../darknet/data/
cp obj.data ../darknet/data/  
</div></code></pre>
<h2 id="yolov4">YoloV4</h2>
<p>All the YoloV4 code is develop by <a href="https://github.com/AlexeyAB/darknet">AlexeyAB/darknet</a>, there you can find great documentation and examples about how to train, metrics, etc.</p>
<h3 id="compiling-yolov4-on-nvidia-jetson-nano">Compiling YoloV4 on Nvidia Jetson Nano</h3>
<p>First of all you have to clone <a href="https://github.com/AlexeyAB/darknet">AlexeyAB repository</a></p>
<pre class="hljs"><code><div>$ git clone https://github.com/AlexeyAB/darknet.git
$ cd darknet
</div></code></pre>
<p>Edit the Makefile with:</p>
<pre class="hljs"><code><div>GPU=1
CUDNN=1
CUDNN_HALF=1
OPENCV=1
AVX=0
OPENMP=1
LIBSO=1
ZED_CAMERA=0
ZED_CAMERA_v2_8=0

......

USE_CPP=0
DEBUG=0

ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]

......

NVCC=/usr/local/cuda/bin/nvcc

</div></code></pre>
<p>And run make:</p>
<pre class="hljs"><code><div>$ make
</div></code></pre>
<h3 id="testing-yolov4-with-coco">Testing YoloV4 with COCO</h3>
<p>After that the project is compiled and just need the trained weights to run it. I recommend to use Tiny-Yolo if you want a higher FPS performance. You can download both from AlexeyAB repository:</p>
<ul>
<li><a href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights">yolov4.weights</a></li>
<li><a href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights">yolov4-tiny.weights</a></li>
</ul>
<p>To run darknet just:</p>
<pre class="hljs"><code><div>./darknet detector demo cfg/coco.data \
                          cfg/yolov4-tiny.cfg \
                          yolov4-tiny.weights \
                          -c 0
</div></code></pre>
<p>The <code>-c 0</code> means using the camera (V4L2) device at <code>/dev/video0</code>.</p>
<h3 id="training-the-mask-detector">Training the Mask Detector</h3>
<p>To train a new YoloV4-Tiny model just follow <a href="https://github.com/AlexeyAB/darknet#how-to-train-tiny-yolo-to-detect-your-custom-objects">AlexeyAB steps</a> or use my files and .weights. It takes about 20 hours to finish the 6000 steps (2000x3 classes).</p>
<p>To run with my trainning:</p>
<pre class="hljs"><code><div>./darknet detector demo cfg/obj.data \
                          cfg/yolov4-tiny-masks.cfg \
                          yolov4-tiny-obj_last.weights \
                          -c 0
</div></code></pre>
<h3 id="led-control">Led Control</h3>
<p>To finish the project I wanted to use this detections to create &quot;traffic lights&quot;, that's just a silly experiment but the possibilities are endless...</p>
<p>Once you have the model loaded you can run it from darknet_video.py or darknet_images.py, on this case I use darknet_images.py <code>import RPi.GPIO as GPIO </code> and added an if-else statement to control detections and set high-low values to the pins output.</p>
<p>The circuit I created if this one with 2 leds and 2 PN2222 transistors one for the green led and the other one for the red.
<img src="images/Circuit.jpeg" alt="Circuit"></p>
<p>The pins are mapped this way:</p>
<pre class="hljs"><code><div>    pinGreen =  18 #Green led -&gt; Pin 12 on the board
    pinRed = 24 #Red led -&gt; Pin 18 on the board
</div></code></pre>
<p>Thats an useful image to see how BCM maps works:</p>
<p><img src="images/JetsonNano-pinout.png" alt="JetsonNano Pinout"></p>
<p>Live demo:</p>
<p><img src="images/LedControl.gif" alt="Led Control"></p>

</body>
</html>
